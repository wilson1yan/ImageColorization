{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from image_colorization import *\n",
    "from utils import *\n",
    "from optim import *\n",
    "from fusion_model import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlacesDataset(data.Dataset):\n",
    "    def __init__(self, root, n=None, n_classes=None):\n",
    "        super(PlacesDataset, self).__init__()\n",
    "        self.categories = [os.path.basename(fname) for fname in glob.glob(os.path.join(root, '*'))]\n",
    "        if n_classes is not None:\n",
    "            self.categories = random.sample(self.categories, n_classes)\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.images_per_category = pickle.load(open('images_per_category', 'rb'))\n",
    "        self.images_per_category = {k: self.images_per_category[k] for k in self.categories}\n",
    "        if n is not None:\n",
    "            for c in self.images_per_category:\n",
    "                self.images_per_category[c] = random.sample(self.images_per_category[c], n)\n",
    "        \n",
    "        self.name_id_map = {cat: i for i, cat in enumerate(self.categories)}\n",
    "        self.id_name_map = {v: k for k, v in self.name_id_map.items()}\n",
    "        self.size = sum([len(v) for v in self.images_per_category.values()])\n",
    "        \n",
    "    def category_from_path(self, path):\n",
    "        folder = os.path.basename(os.path.split(path)[0])\n",
    "        return self.name_id_map[folder]\n",
    "        \n",
    "    def load_process_image(self, image_path):\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((224, 224))\n",
    "        image_lab = color.rgb2lab(np.array(image))\n",
    "        image_lab = image_lab.transpose(2, 0, 1)\n",
    "        input, label = image_lab[0, :, :] - 50, image_lab[1:, :, :]\n",
    "        label = (label + 128) / 256\n",
    "        return torch.FloatTensor(input).unsqueeze(0), torch.FloatTensor(label)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if index >= len(self):\n",
    "            raise IndexError('Index %s out of range for size %s' % (index, len(self)))\n",
    "        for c, images in self.images_per_category.items():\n",
    "            if index >= len(images):\n",
    "                index -= len(images)\n",
    "            else:\n",
    "                break\n",
    "        image_path = self.images_per_category[c][index]\n",
    "        category = self.category_from_path(image_path)\n",
    "        input, ab_label = self.load_process_image(image_path)\n",
    "        return input, ab_label, category\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, alpha, optimizer, loader, num_epochs=10, show_every=20):\n",
    "    losses = []\n",
    "    criterion_ab, criterion_class = nn.MSELoss(), nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch %s' % epoch)\n",
    "        print('=' * 10)\n",
    "        \n",
    "        running_loss = []\n",
    "        for i, data in enumerate(iter(loader)):\n",
    "            input, label_ab, label_cat = data\n",
    "            input, label_ab, label_cat = Variable(input), Variable(label_ab), Variable(label_cat)\n",
    "            output_ab, output_cat = model(input, input)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_ab = criterion_ab(output_ab, label_ab)\n",
    "            loss_class = criterion_class(output_cat, label_cat)\n",
    "            loss = loss_ab + alpha * loss_class\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss.append(loss.data[0])\n",
    "            if show_every is not None and i % show_every == 0:\n",
    "                print('Iter %s: %s' % (i, np.mean(running_loss)))\n",
    "        print('Average loss: %s' % (np.mean(running_loss)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, dset):\n",
    "    input, label, category = dset[random.choice(np.arange(len(dset)))]\n",
    "    L = input.numpy() + 50\n",
    "    input = Variable(input.unsqueeze(0))\n",
    "    out_ab, out_cat = model(input, input)\n",
    "    out_ab, out_cat = out_ab.squeeze(0), out_cat.squeeze(0)\n",
    "    _, out_cat = torch.max(out_cat, 0)\n",
    "    print(dset.id_name_map[out_cat.data[0]])\n",
    "\n",
    "    actual_ab = label.numpy() * 256 - 128\n",
    "    actual = np.concatenate((L, actual_ab), axis=0).transpose(1, 2, 0)\n",
    "    actual = color.lab2rgb(actual.astype(np.float64))\n",
    "    \n",
    "    out_ab = out_ab.data.numpy().clip(0, 1) * 256 - 128\n",
    "    pred = np.concatenate((L, out_ab), axis=0).transpose(1, 2, 0)\n",
    "    pred = color.lab2rgb(pred.astype(np.float64))\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.imshow(actual)\n",
    "    ax2.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset = PlacesDataset('data/data/vision/torralba/deeplearning/images256', n=100, n_classes=5)\n",
    "loader = data.DataLoader(dset, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = FusionColorizer(dset.n_classes)\n",
    "optimizer = optim.Adadelta(model.parameters())\n",
    "alpha = 1/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "==========\n",
      "Average loss: 0.0167534859502\n",
      "Epoch 1\n",
      "==========\n",
      "Average loss: 0.010117443162\n",
      "Epoch 2\n",
      "==========\n",
      "Average loss: 0.00934561429312\n",
      "Epoch 3\n",
      "==========\n",
      "Average loss: 0.00994461291702\n",
      "Epoch 4\n",
      "==========\n",
      "Average loss: 0.0132441690657\n",
      "Epoch 5\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, alpha, optimizer, loader, num_epochs=100, show_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
